{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>data</th>\n",
       "      <th>label</th>\n",
       "      <th>object:name</th>\n",
       "      <th>object:instance</th>\n",
       "      <th>object:status</th>\n",
       "      <th>action:name</th>\n",
       "      <th>action:status</th>\n",
       "      <th>org:actor:name</th>\n",
       "      <th>org:actor:instance</th>\n",
       "      <th>org:passive:name</th>\n",
       "      <th>org:passive:instance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>accept order</td>\n",
       "      <td>['Automated activity', 'Physical activity', 'U...</td>\n",
       "      <td>order</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>accept</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>acquire equipment</td>\n",
       "      <td>['Physical activity', 'User activity']</td>\n",
       "      <td>equipment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acquire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>advertise post</td>\n",
       "      <td>['Physical activity', 'User activity']</td>\n",
       "      <td>post</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>advertise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>alert supervisor</td>\n",
       "      <td>['Automated activity', 'Physical activity', 'U...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>alert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>supervisor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>analyze defect</td>\n",
       "      <td>['Physical activity', 'User activity']</td>\n",
       "      <td>defect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>analyze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0               data  \\\n",
       "0           0       accept order   \n",
       "1           1  acquire equipment   \n",
       "2           2     advertise post   \n",
       "3           3   alert supervisor   \n",
       "4           4     analyze defect   \n",
       "\n",
       "                                               label object:name  \\\n",
       "0  ['Automated activity', 'Physical activity', 'U...       order   \n",
       "1             ['Physical activity', 'User activity']   equipment   \n",
       "2             ['Physical activity', 'User activity']        post   \n",
       "3  ['Automated activity', 'Physical activity', 'U...         NaN   \n",
       "4             ['Physical activity', 'User activity']      defect   \n",
       "\n",
       "   object:instance  object:status action:name  action:status  org:actor:name  \\\n",
       "0              NaN            NaN      accept            NaN             NaN   \n",
       "1              NaN            NaN     acquire            NaN             NaN   \n",
       "2              NaN            NaN   advertise            NaN             NaN   \n",
       "3              NaN            NaN       alert            NaN             NaN   \n",
       "4              NaN            NaN     analyze            NaN             NaN   \n",
       "\n",
       "   org:actor:instance org:passive:name  org:passive:instance  \n",
       "0                 NaN              NaN                   NaN  \n",
       "1                 NaN              NaN                   NaN  \n",
       "2                 NaN              NaN                   NaN  \n",
       "3                 NaN       supervisor                   NaN  \n",
       "4                 NaN              NaN                   NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapath = f'../../src/datasets/01_basic_dataset_for_classification.csv'\n",
    "df = pd.read_csv(datapath)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accept order</td>\n",
       "      <td>['Automated activity', 'Physical activity', 'U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acquire equipment</td>\n",
       "      <td>['Physical activity', 'User activity']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>advertise post</td>\n",
       "      <td>['Physical activity', 'User activity']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alert supervisor</td>\n",
       "      <td>['Automated activity', 'Physical activity', 'U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>analyze defect</td>\n",
       "      <td>['Physical activity', 'User activity']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                text                                             labels\n",
       "0       accept order  ['Automated activity', 'Physical activity', 'U...\n",
       "1  acquire equipment             ['Physical activity', 'User activity']\n",
       "2     advertise post             ['Physical activity', 'User activity']\n",
       "3   alert supervisor  ['Automated activity', 'Physical activity', 'U...\n",
       "4     analyze defect             ['Physical activity', 'User activity']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df[['data', 'label']]\n",
    "df=df.rename(columns={'data':'text', 'label':'labels'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {\"['Physical activity', 'User activity']\":0,\n",
    "          \"['Automated activity', 'Physical activity', 'User activity']\":0,\n",
    "          \"['Physical activity']\":1,\n",
    "          \"['User activity']\":2,\n",
    "          \"['Automated activity', 'User activity']\":0\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df.labels.apply(lambda x: labels[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accept order</td>\n",
       "      <td>['Automated activity', 'Physical activity', 'U...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acquire equipment</td>\n",
       "      <td>['Physical activity', 'User activity']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>advertise post</td>\n",
       "      <td>['Physical activity', 'User activity']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alert supervisor</td>\n",
       "      <td>['Automated activity', 'Physical activity', 'U...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>analyze defect</td>\n",
       "      <td>['Physical activity', 'User activity']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                text                                             labels  \\\n",
       "0       accept order  ['Automated activity', 'Physical activity', 'U...   \n",
       "1  acquire equipment             ['Physical activity', 'User activity']   \n",
       "2     advertise post             ['Physical activity', 'User activity']   \n",
       "3   alert supervisor  ['Automated activity', 'Physical activity', 'U...   \n",
       "4     analyze defect             ['Physical activity', 'User activity']   \n",
       "\n",
       "   sentiment  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='labels'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.groupby(['labels']).size().plot.bar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='sentiment'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.groupby(['sentiment']).size().plot.bar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['Automated activity', 'Physical activity', 'User activity']\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Physical activity', 'User activity']                          231\n",
       "['Automated activity', 'Physical activity', 'User activity']     58\n",
       "['Physical activity']                                            25\n",
       "['User activity']                                                12\n",
       "['Automated activity', 'User activity']                          11\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPReviewDataset(Dataset):\n",
    "\n",
    "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
    "    self.reviews = reviews\n",
    "    self.targets = targets\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_len = max_len\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.reviews)\n",
    "  \n",
    "  def __getitem__(self, item):\n",
    "    review = str(self.reviews[item])\n",
    "    target = self.targets[item]\n",
    "\n",
    "    encoding = self.tokenizer.encode_plus(\n",
    "      review,\n",
    "      add_special_tokens=True,\n",
    "      max_length=self.max_len,\n",
    "      return_token_type_ids=False,\n",
    "      pad_to_max_length=True,\n",
    "      return_attention_mask=True,\n",
    "      return_tensors='pt',\n",
    "    )\n",
    "\n",
    "    return {\n",
    "      'review_text': review,\n",
    "      'input_ids': encoding['input_ids'].flatten(),\n",
    "      'attention_mask': encoding['attention_mask'].flatten(),\n",
    "      'targets': torch.tensor(target, dtype=torch.long)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 160\n",
    "RANDOM_SEED=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.1, random_state=RANDOM_SEED)\n",
    "df_val, df_test = train_test_split(df_test, test_size=0.5, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((303, 3), (17, 3), (17, 3))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "  ds = GPReviewDataset(\n",
    "    reviews=df.text.to_numpy(),\n",
    "    targets=df.sentiment.to_numpy(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=max_len\n",
    "  )\n",
    "\n",
    "  return DataLoader(\n",
    "    ds,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=4\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data = next(iter(train_data_loader))\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentClassifier(nn.Module):\n",
    "\n",
    "  def __init__(self, n_classes):\n",
    "    super(SentimentClassifier, self).__init__()\n",
    "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "    self.drop = nn.Dropout(p=0.3)\n",
    "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "  \n",
    "  def forward(self, input_ids, attention_mask):\n",
    "    _, pooled_output = self.bert(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask\n",
    "    )\n",
    "    output = self.drop(pooled_output)\n",
    "    return self.out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.sentiment.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = SentimentClassifier(len(df.sentiment.value_counts()))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = data['input_ids'].to(device)\n",
    "attention_mask = data['attention_mask'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.Softmax(model(input_ids, attention_mask), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "  optimizer,\n",
    "  num_warmup_steps=0,\n",
    "  num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "  model, \n",
    "  data_loader, \n",
    "  loss_fn, \n",
    "  optimizer, \n",
    "  device, \n",
    "  scheduler, \n",
    "  n_examples\n",
    "):\n",
    "  model = model.train()\n",
    "\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "  \n",
    "  for d in data_loader:\n",
    "    input_ids = d[\"input_ids\"].to(device)\n",
    "    attention_mask = d[\"attention_mask\"].to(device)\n",
    "    targets = d[\"targets\"].to(device)\n",
    "\n",
    "    outputs = model(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask\n",
    "    )\n",
    "\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    loss = loss_fn(outputs, targets)\n",
    "\n",
    "    correct_predictions += torch.sum(preds == targets)\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "  model = model.eval()\n",
    "\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for d in data_loader:\n",
    "      input_ids = d[\"input_ids\"].to(device)\n",
    "      attention_mask = d[\"attention_mask\"].to(device)\n",
    "      targets = d[\"targets\"].to(device)\n",
    "\n",
    "      outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask\n",
    "      )\n",
    "      _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "      loss = loss_fn(outputs, targets)\n",
    "\n",
    "      correct_predictions += torch.sum(preds == targets)\n",
    "      losses.append(loss.item())\n",
    "\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "  print('-' * 10)\n",
    "\n",
    "  train_acc, train_loss = train_epoch(\n",
    "    model,\n",
    "    train_data_loader,    \n",
    "    loss_fn, \n",
    "    optimizer, \n",
    "    device, \n",
    "    scheduler, \n",
    "    len(df_train)\n",
    "  )\n",
    "\n",
    "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "  val_acc, val_loss = eval_model(\n",
    "    model,\n",
    "    val_data_loader,\n",
    "    loss_fn, \n",
    "    device, \n",
    "    len(df_val)\n",
    "  )\n",
    "\n",
    "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "  print()\n",
    "\n",
    "  history['train_acc'].append(train_acc)\n",
    "  history['train_loss'].append(train_loss)\n",
    "  history['val_acc'].append(val_acc)\n",
    "  history['val_loss'].append(val_loss)\n",
    "\n",
    "  if val_acc > best_accuracy:\n",
    "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "    best_accuracy = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['train_acc'], label='train accuracy')\n",
    "plt.plot(history['val_acc'], label='validation accuracy')\n",
    "\n",
    "plt.title('Training history')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.ylim([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc, _ = eval_model(\n",
    "  model,\n",
    "  test_data_loader,\n",
    "  loss_fn,\n",
    "  device,\n",
    "  len(df_test)\n",
    ")\n",
    "\n",
    "test_acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, data_loader):\n",
    "  model = model.eval()\n",
    "  \n",
    "  review_texts = []\n",
    "  predictions = []\n",
    "  prediction_probs = []\n",
    "  real_values = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for d in data_loader:\n",
    "\n",
    "      texts = d[\"review_text\"]\n",
    "      input_ids = d[\"input_ids\"].to(device)\n",
    "      attention_mask = d[\"attention_mask\"].to(device)\n",
    "      targets = d[\"targets\"].to(device)\n",
    "\n",
    "      outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask\n",
    "      )\n",
    "      \n",
    "      _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "      probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "      review_texts.extend(texts)\n",
    "      predictions.extend(preds)\n",
    "      prediction_probs.extend(probs)\n",
    "      real_values.extend(targets)\n",
    "\n",
    "  predictions = torch.stack(predictions).cpu()\n",
    "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
    "  real_values = torch.stack(real_values).cpu()\n",
    "  return review_texts, predictions, prediction_probs, real_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
    "  model,\n",
    "  test_data_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred)#, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertweetTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"vinai/bertweet-base\")#('bert-base-cased')\n",
    "labels = {\"['Physical activity', 'User activity']\":0,\n",
    "          \"['Automated activity', 'Physical activity', 'User activity']\":1,\n",
    "          \"['Physical activity']\":2,\n",
    "          \"['User activity']\":3,\n",
    "          \"['Automated activity', 'User activity']\":4\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "\n",
    "        self.labels = [labels[label] for label in df['labels']]\n",
    "        self.texts = [tokenizer(text, \n",
    "                               padding=True, max_length = 512, truncation=True,\n",
    "                                return_tensors=\"pt\") for text in df['text']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5):\n",
    "\n",
    "        super(BertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained(\"vinai/bertweet-base\")\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_label=train_label.type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data, val_data, learning_rate, epochs):\n",
    "\n",
    "    train, val = Dataset(train_data), Dataset(val_data)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "            model = model.cuda()\n",
    "            criterion = criterion.cuda()\n",
    "\n",
    "    \n",
    "    for epoch_num in range(epochs):\n",
    "\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "\n",
    "            for train_input, train_label in tqdm(train_dataloader):\n",
    "\n",
    "                \n",
    "                mask = train_input['attention_mask'].to(device)\n",
    "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                output = model(input_id, mask)\n",
    "                \n",
    "                train_label=train_label.type(torch.LongTensor)\n",
    "                train_label = train_label.to(device)\n",
    "                batch_loss = criterion(output, train_label)\n",
    "                total_loss_train += batch_loss.item()\n",
    "                \n",
    "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "                total_acc_train += acc\n",
    "\n",
    "                model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            \n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for val_input, val_label in val_dataloader:\n",
    "\n",
    "                    val_label = val_label.to(device)\n",
    "                    mask = val_input['attention_mask'].to(device)\n",
    "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                    output = model(input_id, mask)\n",
    "\n",
    "                    val_label=val_label.type(torch.LongTensor)\n",
    "                    val_label = val_label.to(device)\n",
    "                    batch_loss = criterion(output, val_label)\n",
    "                    total_loss_val += batch_loss.item()\n",
    "                    \n",
    "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                    total_acc_val += acc\n",
    "            \n",
    "            print(f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} | Train Accuracy: {total_acc_train / len(train_data): .3f} | Val Loss: {total_loss_val / len(val_data): .3f} | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_data):\n",
    "    test = Dataset(test_data)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    total_acc_test = 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for test_input, test_label in test_dataloader:\n",
    "\n",
    "              test_label = test_label.to(device)\n",
    "              mask = test_input['attention_mask'].to(device)\n",
    "              input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "              output = model(input_id, mask)\n",
    "\n",
    "              acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "              total_acc_test += acc\n",
    "    \n",
    "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evaluate(model, test_data):\n",
    "    test = Dataset(test_data)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    predictions = []\n",
    "    prediction_probs = []\n",
    "    real_values = []\n",
    "\n",
    "    total_acc_test = 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for test_input, test_label in test_dataloader:\n",
    "\n",
    "            test_label = test_label.to(device)\n",
    "            mask = test_input['attention_mask'].to(device)\n",
    "            input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            outputs = model(input_id, mask)\n",
    "            \n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "            probs = F.Softmax(outputs, dim=1)\n",
    "            \n",
    "            predictions.extend(preds)\n",
    "            prediction_probs.extend(probs)\n",
    "            real_values.extend(test_label)\n",
    "            \n",
    "    predictions = torch.stack(predictions).cpu()\n",
    "    prediction_probs = torch.stack(prediction_probs).cpu()\n",
    "    real_values = torch.stack(real_values).cpu()\n",
    "    return predictions, prediction_probs, real_values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269 34 34\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(112)\n",
    "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42), \n",
    "                                     [int(.8*len(df)), int(.9*len(df))])\n",
    "\n",
    "print(len(df_train),len(df_val), len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing BertModel: ['roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.embeddings.LayerNorm.weight', 'roberta.embeddings.position_ids', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.pooler.dense.bias', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'lm_head.decoder.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'lm_head.decoder.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.6.attention.self.value.bias', 'lm_head.dense.weight', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.pooler.dense.weight', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.9.attention.self.value.weight', 'lm_head.dense.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.output.dense.weight', 'lm_head.bias', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.3.attention.self.key.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.3.intermediate.dense.bias', 'pooler.dense.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.6.attention.self.value.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.5.attention.self.key.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.5.output.LayerNorm.bias', 'pooler.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.7.attention.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\kiran.busch\\OneDrive - Khne Logistics University\\project collab mannheim\\git\\env\\rpa\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36mconvert_to_tensors\u001b[1;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 705\u001b[1;33m                     \u001b[0mtensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Could not infer dtype of NoneType",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\KIRAN~1.BUS\\AppData\\Local\\Temp/ipykernel_16692/3090522060.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mLR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e-6\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\KIRAN~1.BUS\\AppData\\Local\\Temp/ipykernel_16692/78188101.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, train_data, val_data, learning_rate, epochs)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtrain_dataloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\KIRAN~1.BUS\\AppData\\Local\\Temp/ipykernel_16692/2893118304.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, df)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'labels'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         self.texts = [tokenizer(text, \n\u001b[0m\u001b[0;32m      7\u001b[0m                                \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                                 return_tensors=\"pt\") for text in df['text']]\n",
      "\u001b[1;32mC:\\Users\\KIRAN~1.BUS\\AppData\\Local\\Temp/ipykernel_16692/2893118304.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'labels'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         self.texts = [tokenizer(text, \n\u001b[0m\u001b[0;32m      7\u001b[0m                                \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                                 return_tensors=\"pt\") for text in df['text']]\n",
      "\u001b[1;32mc:\\Users\\kiran.busch\\OneDrive - Khne Logistics University\\project collab mannheim\\git\\env\\rpa\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2386\u001b[0m             )\n\u001b[0;32m   2387\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2388\u001b[1;33m             return self.encode_plus(\n\u001b[0m\u001b[0;32m   2389\u001b[0m                 \u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2390\u001b[0m                 \u001b[0mtext_pair\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kiran.busch\\OneDrive - Khne Logistics University\\project collab mannheim\\git\\env\\rpa\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode_plus\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2456\u001b[0m         )\n\u001b[0;32m   2457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2458\u001b[1;33m         return self._encode_plus(\n\u001b[0m\u001b[0;32m   2459\u001b[0m             \u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2460\u001b[0m             \u001b[0mtext_pair\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kiran.busch\\OneDrive - Khne Logistics University\\project collab mannheim\\git\\env\\rpa\\lib\\site-packages\\transformers\\tokenization_utils.py\u001b[0m in \u001b[0;36m_encode_plus\u001b[1;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    462\u001b[0m         \u001b[0msecond_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtext_pair\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m         return self.prepare_for_model(\n\u001b[0m\u001b[0;32m    465\u001b[0m             \u001b[0mfirst_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m             \u001b[0mpair_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msecond_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kiran.busch\\OneDrive - Khne Logistics University\\project collab mannheim\\git\\env\\rpa\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36mprepare_for_model\u001b[1;34m(self, ids, pair_ids, add_special_tokens, padding, truncation, max_length, stride, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, prepend_batch_axis, **kwargs)\u001b[0m\n\u001b[0;32m   2917\u001b[0m             \u001b[0mencoded_inputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"length\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded_inputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"input_ids\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2918\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2919\u001b[1;33m         batch_outputs = BatchEncoding(\n\u001b[0m\u001b[0;32m   2920\u001b[0m             \u001b[0mencoded_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprepend_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprepend_batch_axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2921\u001b[0m         )\n",
      "\u001b[1;32mc:\\Users\\kiran.busch\\OneDrive - Khne Logistics University\\project collab mannheim\\git\\env\\rpa\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_sequences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_sequences\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtensor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprepend_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprepend_batch_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kiran.busch\\OneDrive - Khne Logistics University\\project collab mannheim\\git\\env\\rpa\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36mconvert_to_tensors\u001b[1;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[0;32m    719\u001b[0m                         \u001b[1;34m\"Please see if a fast version of this tokenizer is available to have this feature available.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    720\u001b[0m                     )\n\u001b[1;32m--> 721\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    722\u001b[0m                     \u001b[1;34m\"Unable to create tensor, you should probably activate truncation and/or padding \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    723\u001b[0m                     \u001b[1;34m\"with 'padding=True' 'truncation=True' to have batched tensors with the same length.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length."
     ]
    }
   ],
   "source": [
    "EPOCHS = 2\n",
    "model = BertClassifier()\n",
    "LR = 1e-6\n",
    "              \n",
    "train(model, df_train, df_val, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.294\n"
     ]
    }
   ],
   "source": [
    "evaluate(model, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got multiple values for argument 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\KIRAN~1.BUS\\AppData\\Local\\Temp/ipykernel_16956/83184106.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\KIRAN~1.BUS\\AppData\\Local\\Temp/ipykernel_16956/1505351202.py\u001b[0m in \u001b[0;36mget_evaluate\u001b[1;34m(model, test_data)\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m             \u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got multiple values for argument 'dim'"
     ]
    }
   ],
   "source": [
    "get_evaluate(model, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, data_loader):\n",
    "  model = model.eval()\n",
    "  \n",
    "  review_texts = []\n",
    "  predictions = []\n",
    "  prediction_probs = []\n",
    "  real_values = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for d in data_loader:\n",
    "\n",
    "      texts = d[\"review_text\"]\n",
    "      input_ids = d[\"input_ids\"].to(device)\n",
    "      attention_mask = d[\"attention_mask\"].to(device)\n",
    "      targets = d[\"targets\"].to(device)\n",
    "\n",
    "      outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask\n",
    "      )\n",
    "      _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "      probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "      review_texts.extend(texts)\n",
    "      predictions.extend(preds)\n",
    "      prediction_probs.extend(probs)\n",
    "      real_values.extend(targets)\n",
    "\n",
    "  predictions = torch.stack(predictions).cpu()\n",
    "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
    "  real_values = torch.stack(real_values).cpu()\n",
    "  return review_texts, predictions, prediction_probs, real_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertClassifier(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (linear): Linear(in_features=768, out_features=5, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "89893cb23d3dcc86259f378cdfae0017b55a19df352dd69d184048d73a3ee7ed"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('rpa': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
